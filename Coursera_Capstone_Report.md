# Coursera Capstone Report: San Francisco Crime 
### By: Ketan M, July 23, 2021

## Part 1 Introduction:

#### 1.1 Background:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;San Francisco is a huge city with a diverse and large population. It is home to many and provides numerous jobs and opportunities. Throughout San Francisco, there are many areas with high crime rates. These high crime rates can influence where people shop to where people live. Each year the crime rates in different areas change, resulting in a different environment. Looking at the rate and type of crime in a multitude of areas is really important in order to ensure your well-being. This information, derived from crime reports by the San Francisco Police Department, can tell you where are the safest places to travel or safest routes in the city. Obviously, this data can be very useful in order to keep the city safe. 

#### 1.2 Problem:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;There are two main problems that the data will solve. First, it will find which areas have the highest crime rate in certain months of a year and plot that on interactive maps. The data will also find the nearest venue, distance, and San Francisco crime to an address that the user chooses. Secondly, the data will also be used to find the top 3 types of crimes in each district and compare and group each district to each other based on the type of crime and frequency. I will use the KMeans model to solve this. Basically, problem one is to find where are most of the crimes in San Francisco located and the second problem is which are the most common types of crime in San Francisco. 

#### 1.3 Interest:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tourists and the police would be interested in the results of this project for many reasons. Firstly, Tourists can figure out where are the safest places to travel and the safest routes in San Francisco. Secondly, the police can figure out where to send their patrolling officers based on the type of crime and frequency of crime. This can make the San Francisco streets safer for everybody. Therefore, this project can contribute much-needed information to the general public.

## Part 2 Data Acquisition and Cleaning:

#### 2.1 Data Sources:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I will use Kaggle datasets and Foursquare location data in order to solve the problems. I will use the "San Francisco Crime Classification" dataset in Kaggle, and here is the link to it https://www.kaggle.com/kaggle/san-francisco-crime-classification. This has data about San Francisco crimes from 2003 to 2015. I will also use a multitude of libraries. The libraries I will use are Folium, Pandas, Numpy, Requests, Sklearn, Matplotlib, Geopy, and some data booting libraries. The data and libraries will help me perform the data analysis and result in some interesting conclusions. 

#### 2.2 Data Cleaning: 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I started off by downloading the test.csv data from the Kaggle data set. Since two questions need to be solved, I copied the data set over to another data set. So, I have two data sets, sf_crime_1, representing the first question, and sf_crime_2, representing the second question.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The first problem I encounter is that the timestamp is in one column. I want the timestamp to be split into years, months, days, hours, and minutes in order to get the data in a specific interval. So, for both data sets, I normalize the timestamps using the pandas to_datetime method and then put each unit of time into columns. So I basically split the timestamps into 5 columns representing units of time. This occurs in both data sets. 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;To solve the first question, we need to use the frequency of the locations of the crimes. So, if there are crimes with the same location, I will keep them in order to produce an accurate model. Also, there is a bunch of useless information that has nothing to do with this question, so, in the feature selection section, I will discard the useless information. 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;To solve the second question, we need to use the frequency of the category of crime. So, if there are redundant locations and categories, I will keep them in order to produce an accurate model. Once again, there is a lot of data that has nothing to do with this question, so, in the feature selection section, I will discard the useless information. 

#### 2.3 Feature Selection
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The two data sets have a lot of information that does not help get the answers to the problems. So, in order to lower the size of the data, I remove information that does not relate to the problem. 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In the first data set, sf_crime_1, I start off with 878049 samples and 14 features. Now, a lot of this information is useless. So I remove them. I remove the Timestamp, Category, Description, Day of the Week, Resolution, Day, Hour, and Minute. I do not remove the year and the months because I want to create an interval for the data in order to reduce the number of samples. So, I only choose the samples from the first four months of 2014. Now I have 24228 samples and 6 features, the features being the District, Address, Latitude, Longitude, Year, and Month. I also reset the index here. This question has three main parts, so I copy this data into three data sets, sf_crime_cluster, sf_crime_heat, and sf_crime_venue. These data sets are used to create a cluster marker map, a heat map, and a venue finding algorithm. 

<img width="488" alt="Screen Shot 2021-07-20 at 10 52 59 AM" src="https://user-images.githubusercontent.com/76541886/126372340-0b3afe90-8e75-4840-b84b-c8d4ad99010e.png">

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In the second data set, sf_crime_2, I once again start off with 878049 samples and 14 features. Now since the frequency of crime in a district is needed, keeping all the samples is important in order to get an accurate model. Also, since we are classifying only 10 districts, the runtime should be relatively quick. In this data set, I also drop some features. I remove the Timestamp, Day of the Week, Resolution, Month, Day, Hour, and Minute. So now I have 878049 samples and 7 features, the features being Category, Description, District, Address, Latitude, Longitude, and Year. Using this data set and other libraries, I can create more data sets that can solve the question. 

<img width="814" alt="Screen Shot 2021-07-20 at 11 05 45 AM" src="https://user-images.githubusercontent.com/76541886/126373550-b715bb16-4bc4-4133-9e2d-f54ecb45aa3b.png">

## Part 3 Data Methodology:

### Problem 1:

#### 3.1 Description of Code:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;After the data cleaning process, I started to code a visualization of the data in order to solve the problem. So first, I created a marker cluster map. It can help find where crimes are located. I imported the Marker Cluster library from Folium.Plugins and then started to create a Folium Cluster map. I started by creating a folium map called marker_cluster_map with the coordinates on San Francisco, a starting zoom of 12, and the ability to display a control scale. From there, I got the Latitude and Longitude values from the sf_crime_cluster data set and put them into a list so I can plot the points on the map. Then I iterated through the data set to get the Districts and Addresses and put them into a list so each point can be labeled. I then defined the marker cluster part of the map through an object called MarkerCluster. The MarkerCluster object has parameters for the locations of the crimes and the labels of the crimes, both of which were defined earlier. I then added this MarkerCluster object to the map and then displayed the map. The results will be shown later in the Results part of this report. 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;After creating the Marker Cluster map, I thought it would be more helpful to create a Heat Map as well. Heat Maps are more interpretable than Marker Cluster Maps and they find the density of crimes. So, you can determine where most of the crimes are. So, I start by importing the Heat Map library from Folium.Plugins. I then create a folium map with the same parameters as before. The coordinates are on San Francisco, the start zoom is 12, and the map has a control scale. I then get the locations of each crime using the sf_crime_heat data set. Since heat maps do not have markers, I do not need to get the district name and address as done with the Marker Cluster map. I then create a HeatMap object with the locations as the data and the radius of each crime to be 10 units. I add this object to the map and display the map. The results will be shown later in the Results part of this report. 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;After I visualize the data and solve the main problem. I want to create something extra that can find the nearest venue to the location that a user inputs. I want it to also find the distance to the nearest crime in San Francisco and the nearest San Francisco Crime. So first I start off by defining my Foursquare information. This is hidden for privacy. I then define a getNearbyVenues function which takes a set of coordinates and a name and gets the name of the nearest venue. It works by using the Foursquare API and my information in order to get information about a location. I also define a checking function which basically ensures that the following code does not result in an error using python's try and except functions. From there I create a complicated piece of code that accomplished my goal. In this complicated piece of code, I import Nominatim and distance from geopy. I then create an infinite while loop where the user inputs an address. A Nominatim object is then created and it is used to get information about the address. I then check if the user's address is exit, if so, then I break the while loop and the cell is complete. I then check if the address is is valid using the checking address defined previously. If the address is alright, I get the locations coordinates and San Francisco's crime coordinates and find the least distance between a crime in San Francisco and the address inputed. I then use the getNearbyVenues function to get the nearest venue to the address. I then print out the nearest venue to the crime, the dist
